{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import np_transforms as NP_T\n",
    "from datasets import WebcamTSeq\n",
    "from utils import show_images, sort_seqs_by_len\n",
    "import plotter\n",
    "from collections import OrderedDict\n",
    "from turtle import forward\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn.utils import rnn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# from torchsummary import summary\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_loaders(args_path, args_shape, train_transform, args_gamma, args_batch_size, file_name, args_max_len):\n",
    "    train_data = WebcamTSeq(path=args_path, out_shape=args_shape, transform=train_transform, gamma=args_gamma, max_len=args_max_len, file_name=file_name)\n",
    "    train_loader = DataLoader(train_data,\n",
    "                            batch_size=args_batch_size,\n",
    "                            shuffle=False)  # shuffle the data at the beginning of each epoch\n",
    "\n",
    "    del train_data\n",
    "\n",
    "    return train_loader, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = ['164']\n",
    "data = WebcamTSeq(path='./data/WebCamT', out_shape=[120, 160], transform=NP_T.ToTensor(), gamma=1e3, max_len=6, file_name='164')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(data,batch_size=16,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 3, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "for i, (X,mask,density,count,_,seq_len) in enumerate(test_loader):\n",
    "    print(X.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self, image_dim = None):\n",
    "        super(FCN, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        # FCN layer\n",
    "        self.fcn_blocks = nn.ModuleList()\n",
    "        self.fcn_blocks.append(\n",
    "            nn.Sequential(OrderedDict([\n",
    "                ('Conv1_1', nn.Conv2d(3, 64, (3, 3), padding=1)),\n",
    "                ('ReLU1_1', nn.ReLU()),\n",
    "                ('Conv1_2', nn.Conv2d(64, 64, (3, 3), padding=1)),\n",
    "                ('ReLU1_2', nn.ReLU()),\n",
    "                ('MaxPool1', nn.MaxPool2d((2, 2))),\n",
    "                ('Conv2_1', nn.Conv2d(64, 128, (3, 3), padding=1)),\n",
    "                ('ReLU2_1', nn.ReLU()),\n",
    "                ('Conv2_2', nn.Conv2d(128, 128, (3, 3), padding=1)),\n",
    "                ('ReLU2_2', nn.ReLU()),\n",
    "                ('MaxPool2', nn.MaxPool2d((2, 2))),\n",
    "            ])))\n",
    "        self.fcn_blocks.append(\n",
    "            nn.Sequential(OrderedDict([\n",
    "                ('Conv3_1', nn.Conv2d(128, 256, (3, 3), padding=1)),\n",
    "                ('ReLU3_1', nn.ReLU()),\n",
    "                ('Conv3_2', nn.Conv2d(256, 256, (3, 3), padding=1)),\n",
    "                ('ReLU3_2', nn.ReLU()),\n",
    "                ('Atrous1', nn.Conv2d(256, 256, (3, 3), dilation=2, padding=2)),\n",
    "                ('ReLU_A1', nn.ReLU()),\n",
    "            ])))\n",
    "        self.fcn_blocks.append(\n",
    "            nn.Sequential(OrderedDict([\n",
    "                ('Conv4_1', nn.Conv2d(256, 256, (3, 3), padding=1)),\n",
    "                ('ReLU4_1', nn.ReLU()),\n",
    "                ('Conv4_2', nn.Conv2d(256, 256, (3, 3), padding=1)),\n",
    "                ('ReLU4_2', nn.ReLU()),\n",
    "                ('Atrous2', nn.Conv2d(256, 512, (3, 3), dilation=2, padding=2)),\n",
    "                ('ReLU_A2', nn.ReLU()),\n",
    "            ])))\n",
    "        self.fcn_blocks.append(\n",
    "            nn.Sequential(OrderedDict([\n",
    "                ('Atrous3', nn.Conv2d(512, 512, (3, 3), dilation=2, padding=2)),\n",
    "                ('ReLU_A3', nn.ReLU()),\n",
    "                ('Atrous4', nn.Conv2d(512, 512, (3, 3), dilation=2, padding=2)),\n",
    "                ('ReLU_A4', nn.ReLU()),\n",
    "            ])))\n",
    "        self.fcn_blocks.append(\n",
    "            nn.Sequential(OrderedDict([\n",
    "                ('Conv5', nn.Conv2d(1408, 512, (1, 1))),  # 1408 = 128 + 256 + 512 + 512 (hyper-atrous combination)\n",
    "                ('ReLU5', nn.ReLU()),\n",
    "                ('Deconv1', nn.ConvTranspose2d(512, 256, (3, 3), stride=2, padding=1, output_padding=1)),\n",
    "                ('ReLU_D1', nn.ReLU()),\n",
    "                ('Deconv2', nn.ConvTranspose2d(256, 64, (3, 3), stride=2, padding=1, output_padding=1)),\n",
    "                ('ReLU_D2', nn.ReLU()),\n",
    "                ('Conv6', nn.Conv2d(64, 1, (1, 1))),\n",
    "            ])))\n",
    "    \n",
    "    def forward(self, X, mask=None):\n",
    "        \n",
    "        # X shape = N, L, C, H ,W \n",
    "        N, L, C, H, W = X.shape\n",
    "        X = X.reshape(N*L,C,H,W)\n",
    "        if mask is not None :\n",
    "            mask = mask.reshape(N*L,1,H,W)\n",
    "            X = X * mask\n",
    "            \n",
    "        h1 = self.fcn_blocks[0](X)\n",
    "        h2 = self.fcn_blocks[1](h1)\n",
    "        h3 = self.fcn_blocks[2](h2)\n",
    "        h4 = self.fcn_blocks[3](h3)\n",
    "        h = torch.cat((h1, h2, h3, h4), dim=1) # hyper-atrous combination\n",
    "        h = self.fcn_blocks[4](h)\n",
    "        density = h.reshape(N,L,1,H,W)\n",
    "        if mask is not None :\n",
    "            h = h * mask\n",
    "        \n",
    "        return density, h.sum(dim=(1,2,3)).reshape(N,L) # density & count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FCN                                      --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Sequential: 2-1                   [96, 128, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-1                  [96, 64, 120, 160]        1,792\n",
       "│    │    └─ReLU: 3-2                    [96, 64, 120, 160]        --\n",
       "│    │    └─Conv2d: 3-3                  [96, 64, 120, 160]        36,928\n",
       "│    │    └─ReLU: 3-4                    [96, 64, 120, 160]        --\n",
       "│    │    └─MaxPool2d: 3-5               [96, 64, 60, 80]          --\n",
       "│    │    └─Conv2d: 3-6                  [96, 128, 60, 80]         73,856\n",
       "│    │    └─ReLU: 3-7                    [96, 128, 60, 80]         --\n",
       "│    │    └─Conv2d: 3-8                  [96, 128, 60, 80]         147,584\n",
       "│    │    └─ReLU: 3-9                    [96, 128, 60, 80]         --\n",
       "│    │    └─MaxPool2d: 3-10              [96, 128, 30, 40]         --\n",
       "│    └─Sequential: 2-2                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-11                 [96, 256, 30, 40]         295,168\n",
       "│    │    └─ReLU: 3-12                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-13                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-14                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-15                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-16                   [96, 256, 30, 40]         --\n",
       "│    └─Sequential: 2-3                   [96, 512, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-17                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-18                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-19                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-20                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-21                 [96, 512, 30, 40]         1,180,160\n",
       "│    │    └─ReLU: 3-22                   [96, 512, 30, 40]         --\n",
       "│    └─Sequential: 2-4                   [96, 512, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-23                 [96, 512, 30, 40]         2,359,808\n",
       "│    │    └─ReLU: 3-24                   [96, 512, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-25                 [96, 512, 30, 40]         2,359,808\n",
       "│    │    └─ReLU: 3-26                   [96, 512, 30, 40]         --\n",
       "│    └─Sequential: 2-5                   [96, 1, 120, 160]         --\n",
       "│    │    └─Conv2d: 3-27                 [96, 512, 30, 40]         721,408\n",
       "│    │    └─ReLU: 3-28                   [96, 512, 30, 40]         --\n",
       "│    │    └─ConvTranspose2d: 3-29        [96, 256, 60, 80]         1,179,904\n",
       "│    │    └─ReLU: 3-30                   [96, 256, 60, 80]         --\n",
       "│    │    └─ConvTranspose2d: 3-31        [96, 64, 120, 160]        147,520\n",
       "│    │    └─ReLU: 3-32                   [96, 64, 120, 160]        --\n",
       "│    │    └─Conv2d: 3-33                 [96, 1, 120, 160]         65\n",
       "==========================================================================================\n",
       "Total params: 10,864,321\n",
       "Trainable params: 10,864,321\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 2.06\n",
       "==========================================================================================\n",
       "Input size (MB): 22.12\n",
       "Forward/backward pass size (MB): 7800.42\n",
       "Params size (MB): 43.46\n",
       "Estimated Total Size (MB): 7866.00\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_FCN = FCN([120,160])\n",
    "summary(model_FCN, (16,6,3,120,160),device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 1, 120, 160])\n",
      "torch.Size([16, 6, 1, 120, 160])\n",
      "torch.Size([16, 6])\n",
      "torch.Size([16, 6, 1, 120, 160])\n",
      "torch.Size([16, 6])\n"
     ]
    }
   ],
   "source": [
    "for i, (X,mask,density,count,_,seq_len) in enumerate(test_loader):\n",
    "    print(mask.shape)\n",
    "    print(density.shape)\n",
    "    print(count.shape)\n",
    "    density, count = model_FCN(X,mask)\n",
    "    print(density.shape)\n",
    "    print(count.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BiLSTM_Encoder(nn.Module):\n",
    "    def __init__(self, image_dim = None):\n",
    "        super(BiLSTM_Encoder, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        # Bidirectional LSTM layer\n",
    "        H,W = self.image_dim\n",
    "        # lstm, input size = H*W, hidden state size = 100 but bidirectional so double\n",
    "        self.lstm_block = nn.LSTM(H*W,100,num_layers = 3, bidirectional = True, batch_first=True) \n",
    "        self.fc = nn.Linear(200,100) # (enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "    def forward(self, density):\n",
    "        # X shape = N, L, 1, H, W\n",
    "        # count shape = N, L\n",
    "        N,L,C,H,W = density.shape\n",
    "        # count_FCN = density.sum(dim=(2,3,4)).reshape(N,L)\n",
    "        \n",
    "        h = density.reshape(N,L,-1)\n",
    "        h, (hidden, cell) = self.lstm_block(h)\n",
    "        # hidden [-2,:,:] = forward last hidden state, hidden[-1,:,:] = backward last hidden state\n",
    "        \n",
    "        return h, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "BiLSTM_Encoder                           --                        --\n",
       "├─LSTM: 1-1                              [16, 6, 200]              15,924,800\n",
       "├─Linear: 1-2                            --                        20,100\n",
       "==========================================================================================\n",
       "Total params: 15,944,900\n",
       "Trainable params: 15,944,900\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.53\n",
       "==========================================================================================\n",
       "Input size (MB): 7.37\n",
       "Forward/backward pass size (MB): 0.15\n",
       "Params size (MB): 63.78\n",
       "Estimated Total Size (MB): 71.31\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encoder = BiLSTM_Encoder(image_dim = (120,160))\n",
    "summary(model_encoder, [(16,6,1,120,160)],device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 200])\n",
      "torch.Size([6, 16, 100])\n",
      "torch.Size([6, 16, 100])\n"
     ]
    }
   ],
   "source": [
    "for i, (X,mask,density,count,_,seq_len) in enumerate(test_loader):\n",
    "    density, count = model_FCN(X,mask)\n",
    "    en_h, en_hidden, en_cell = model_encoder(density)\n",
    "    print(en_h.shape) # 2 * hidden_dim\n",
    "    print(en_hidden.shape)\n",
    "    print(en_cell.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, image_dim = None):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        self.seq_len = seq_len\n",
    "        H,W = self.image_dim\n",
    "        self.lstm_block = nn.LSTM(H*W,100,num_layers = 3, bidirectional = True, batch_first=True)\n",
    "        \n",
    "        \n",
    "    def forward(self, density, hidden, cell):\n",
    "        # density shape = N, L, 1, H, W \n",
    "        # count shape = N, L\n",
    "        N,L,C,H,W = density.shape\n",
    "       \n",
    "        h = density.reshape(N,L,-1)\n",
    "        h, (hidden, cell) = self.lstm_block(h, (hidden, cell))\n",
    "        \n",
    "        return h, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "Decoder                                  --                        --\n",
       "├─LSTM: 1-1                              [16, 6, 200]              15,924,800\n",
       "==========================================================================================\n",
       "Total params: 15,924,800\n",
       "Trainable params: 15,924,800\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 1.53\n",
       "==========================================================================================\n",
       "Input size (MB): 7.45\n",
       "Forward/backward pass size (MB): 0.15\n",
       "Params size (MB): 63.70\n",
       "Estimated Total Size (MB): 71.30\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_decoder = Decoder(image_dim = (120,160))\n",
    "summary(model_decoder, [(16,6,1,120,160),(6,16,100),(6,16,100)],device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 1, 120, 160])\n",
      "torch.Size([16, 1, 1, 120, 160])\n",
      "torch.Size([16, 5])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([16, 1, 200])\n",
      "torch.Size([6, 16, 100])\n",
      "torch.Size([6, 16, 100])\n"
     ]
    }
   ],
   "source": [
    "for i, (X,mask,density,count,_,seq_len) in enumerate(test_loader):\n",
    "    density, count = model_FCN(X,mask)\n",
    "    print(density[:,:-1].shape)\n",
    "    print(density[:,-1].unsqueeze(1).shape)\n",
    "    print(count[:,:-1].shape)\n",
    "    print(count[:,-1].unsqueeze(1).shape)\n",
    "    en_h, en_hidden, en_cell = model_encoder(density[:,:-1])\n",
    "    de_h, de_hidden, de_cell = model_decoder(density[:,-1].unsqueeze(1), en_hidden, en_cell)\n",
    "    print(de_h.shape) # 2 * hidden_dim\n",
    "    print(de_hidden.shape)\n",
    "    print(de_cell.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Attention, self).__init__()\n",
    "        self.W = nn.Linear(400,200)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(200,1)\n",
    "    def forward(self, x):\n",
    "        # x shape = N, 200\n",
    "        N,D = x.shape\n",
    "        h = self.W(x)\n",
    "        h = self.tanh(h)\n",
    "        a = self.v(h)\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Attention()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 5, 1])\n",
      "torch.Size([16, 5, 1])\n",
      "torch.Size([16, 200])\n",
      "torch.Size([16, 400])\n",
      "torch.Size([16, 1])\n",
      "torch.Size([16, 1])\n",
      "tensor([[367774.4688],\n",
      "        [366877.9375],\n",
      "        [365970.4062],\n",
      "        [367946.8125],\n",
      "        [367126.5938],\n",
      "        [365834.3125],\n",
      "        [365419.9062],\n",
      "        [366542.6875],\n",
      "        [365299.0938],\n",
      "        [366884.7188],\n",
      "        [366753.1562],\n",
      "        [366379.2500],\n",
      "        [366732.5000],\n",
      "        [365885.1250],\n",
      "        [366124.0312],\n",
      "        [366938.3750]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i, (X,mask,density,count,_,seq_len) in enumerate(test_loader):\n",
    "    density, count = model_FCN(X,mask)\n",
    "    en_h, en_hidden, en_cell = model_encoder(density[:,:-1])\n",
    "    de_h, de_hidden, de_cell = model_decoder(density[:,-1].unsqueeze(1), en_hidden, en_cell)\n",
    "    # matrix multiplication of \n",
    "    de_h_view = de_h.view(de_h.shape[0], de_h.shape[2], -1)\n",
    "    score = torch.bmm(en_h, de_h_view)\n",
    "    print(score.shape)\n",
    "    att_dis = F.softmax(score, dim=1)\n",
    "    print(att_dis.shape)\n",
    "    att_val = torch.sum(en_h * att_dis, dim=1)\n",
    "    print(att_val.shape)\n",
    "    con = torch.cat((att_val, de_h.squeeze(1)), dim=1)\n",
    "    print(con.shape)\n",
    "    out = a(con)\n",
    "    print(out.shape)\n",
    "    pred = count[:,-1].unsqueeze(1) + out\n",
    "    print(pred.shape)\n",
    "    print(pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCN_BLA(nn.Module):\n",
    "    def __init__(self, FCN, Encoder, Decoder, image_dim = None, seq_len = 5):\n",
    "        super(FCN_BLA, self).__init__()\n",
    "        self.image_dim = image_dim\n",
    "        self.seq_len = seq_len\n",
    "        self.FCN = FCN(image_dim = image_dim)\n",
    "        self.Encoder = Encoder(image_dim = image_dim)\n",
    "        self.Decoder = Decoder(image_dim = image_dim)\n",
    "\n",
    "        self.W = nn.Linear(400,200)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.v = nn.Linear(200,1)\n",
    "    \n",
    "    def forward(self, X, mask):\n",
    "        # X shape = N, L, C, H, W\n",
    "        # mask shape = N, L\n",
    "        density, count = self.FCN(X,mask)\n",
    "        en_h, en_hidden, en_cell = self.Encoder(density[:,:-1])\n",
    "        de_h, de_hidden, de_cell = self.Decoder(density[:,-1].unsqueeze(1), en_hidden, en_cell)\n",
    "        # Add attention\n",
    "        de_h_view = de_h.view(de_h.shape[0], de_h.shape[2], -1)\n",
    "        score = torch.bmm(en_h, de_h_view)\n",
    "        att_dis = F.softmax(score, dim=1)\n",
    "        att_val = torch.sum(en_h * att_dis, dim=1)\n",
    "        con = torch.cat((att_val, de_h.squeeze(1)), dim=1)\n",
    "        out = self.v(self.tanh(self.W(con)))\n",
    "\n",
    "        pred = count[:,-1].unsqueeze(1) + out\n",
    "        return density, pred\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN_BLA(FCN, BiLSTM_Encoder, Decoder, image_dim = (120,160), seq_len = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "FCN                                      --                        --\n",
       "├─ModuleList: 1-1                        --                        --\n",
       "│    └─Sequential: 2-1                   [96, 128, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-1                  [96, 64, 120, 160]        1,792\n",
       "│    │    └─ReLU: 3-2                    [96, 64, 120, 160]        --\n",
       "│    │    └─Conv2d: 3-3                  [96, 64, 120, 160]        36,928\n",
       "│    │    └─ReLU: 3-4                    [96, 64, 120, 160]        --\n",
       "│    │    └─MaxPool2d: 3-5               [96, 64, 60, 80]          --\n",
       "│    │    └─Conv2d: 3-6                  [96, 128, 60, 80]         73,856\n",
       "│    │    └─ReLU: 3-7                    [96, 128, 60, 80]         --\n",
       "│    │    └─Conv2d: 3-8                  [96, 128, 60, 80]         147,584\n",
       "│    │    └─ReLU: 3-9                    [96, 128, 60, 80]         --\n",
       "│    │    └─MaxPool2d: 3-10              [96, 128, 30, 40]         --\n",
       "│    └─Sequential: 2-2                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-11                 [96, 256, 30, 40]         295,168\n",
       "│    │    └─ReLU: 3-12                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-13                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-14                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-15                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-16                   [96, 256, 30, 40]         --\n",
       "│    └─Sequential: 2-3                   [96, 512, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-17                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-18                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-19                 [96, 256, 30, 40]         590,080\n",
       "│    │    └─ReLU: 3-20                   [96, 256, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-21                 [96, 512, 30, 40]         1,180,160\n",
       "│    │    └─ReLU: 3-22                   [96, 512, 30, 40]         --\n",
       "│    └─Sequential: 2-4                   [96, 512, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-23                 [96, 512, 30, 40]         2,359,808\n",
       "│    │    └─ReLU: 3-24                   [96, 512, 30, 40]         --\n",
       "│    │    └─Conv2d: 3-25                 [96, 512, 30, 40]         2,359,808\n",
       "│    │    └─ReLU: 3-26                   [96, 512, 30, 40]         --\n",
       "│    └─Sequential: 2-5                   [96, 1, 120, 160]         --\n",
       "│    │    └─Conv2d: 3-27                 [96, 512, 30, 40]         721,408\n",
       "│    │    └─ReLU: 3-28                   [96, 512, 30, 40]         --\n",
       "│    │    └─ConvTranspose2d: 3-29        [96, 256, 60, 80]         1,179,904\n",
       "│    │    └─ReLU: 3-30                   [96, 256, 60, 80]         --\n",
       "│    │    └─ConvTranspose2d: 3-31        [96, 64, 120, 160]        147,520\n",
       "│    │    └─ReLU: 3-32                   [96, 64, 120, 160]        --\n",
       "│    │    └─Conv2d: 3-33                 [96, 1, 120, 160]         65\n",
       "==========================================================================================\n",
       "Total params: 10,864,321\n",
       "Trainable params: 10,864,321\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (T): 2.06\n",
       "==========================================================================================\n",
       "Input size (MB): 29.49\n",
       "Forward/backward pass size (MB): 7800.42\n",
       "Params size (MB): 43.46\n",
       "Estimated Total Size (MB): 7873.37\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_FCN, [(16,6,3,120,160),(16,6,1,120,160)],device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 1, 120, 160])\n",
      "torch.Size([16, 1])\n",
      "tensor(39.0529, grad_fn=<DivBackward0>) tensor(2.3514e+10, grad_fn=<DivBackward0>) tensor(4.7028e+09, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for i, (X,mask,density,count,_,seq_len) in enumerate(test_loader):\n",
    "    density_pred, count_pred = model(X,mask)\n",
    "    print(density_pred.shape)\n",
    "    print(count_pred.shape)\n",
    "    N = torch.sum(seq_len)\n",
    "    density_loss = torch.sum((density_pred - density)**2)/(2*N)\n",
    "    count_loss = torch.sum((count_pred[:,-1].unsqueeze(1) - count)**2)/2\n",
    "    loss = density_loss + 0.2 * count_loss\n",
    "    print(density_loss, count_loss, loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8076bc061f97e3217ad450c1541df79973787e36f6a4169d5d3c6972128daea"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
